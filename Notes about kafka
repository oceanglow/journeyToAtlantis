For kafka:
Topic 1: 
Kafka only provides a total order over records within a partition, not between different partitions in a topic. Per-partition ordering combined with the ability to partition data by key is sufficient for most applications. 

However, if you require a total order over records this can be achieved with a topic that has only one partition, though this will mean only one consumer process per consumer group.
however that there cannot be more consumer instances than partitions.

Topic 2: Consumer
Basically, if a source record is already consumed by Consumer1, will it
also get consumed by Consumer2 and Consumer3 all subscribing to the same
topic ?
If all the consumers are part of same consumer group (same group.id config
property), then topic/partition data will be balanced over the all the
consumers.
If all the consumer instances have different consumer groups, then all
messages will broadcast to all consumers

Topic 3: Partitioning and replication are two different things.

Partitioning is for scalability. A topic is partitioned in one or more partitions distributed on different brokers so that more consumers can connect to these brokers in order to receive messages sent to the same topic but from different partitions. Increasing partitions increases scalability and the possibility to have more consumers to get messages from the same topic. Answering your question, each message sent to a topic comes into only one partition (of the topic itself).

Replication is for fault-tolerance. You can specify a replication factor on topic creation and it means that every partition for that topic is replicated more times on different brokers. One replica is the "leader" where producer sends and consumer gets messages; other replicas are "follower" which have copies of messages from the "leader" replica. If the broker which handles the "leader" replica goes down, one of the "follower" becomes leader.
https://stackoverflow.com/questions/44787552/in-kafka-is-each-message-replicated-across-all-partitions-of-a-topic


Topic n: bootstrap_serversedit
Value type is string
Default value is "localhost:9092"
This is for bootstrapping and the producer will only use it for getting metadata (topics, partitions and replicas). The socket connections for sending the actual data will be established based on the broker information returned in the metadata. The format is host1:port1,host2:port2, and the list can be a subset of brokers or a VIP pointing to a subset of brokers.


Partitions enable parallel processing of a Topic stream at consumer side. In case of multiple partitions, a consumer in a group pulls the messages from one of the Topic partitions.

However, while partitions speed up the processing at consumer side, it violates message ordering guarantees. Hence partitions should only be used when there is no requirement of processing Topic messages in the order that these were received in. Having said that messages from a particular partition will still be in order.


Important Kafka documentation:
http://kafka.apache.org/documentation/

Scaling Kafka: adding a broker node and deleting one
https://gquintana.github.io/2016/10/17/Scaling-Kafka.html

Understanding consumer offsets:
https://www.sderosiaux.com/articles/2017/08/07/looking-at-kafka-s-consumers-offsets/

Topic deletion: 
https://jaceklaskowski.gitbooks.io/apache-kafka/kafka-topic-deletion.html

Kafka provides both pub-sub and queue based messaging system. 
Type 1: Workflow of Pub-Sub Messaging
Following is the step wise workflow of the Pub-Sub Messaging âˆ’
1. Producers send message to a topic at regular intervals.
2. Kafka broker stores all messages in the partitions configured for that particular topic. It ensures the messages are equally shared between partitions. If the producer sends two messages and there are two partitions, Kafka will store one message in the first partition and the second message in the second partition.
3. Consumer subscribes to a specific topic.
4. Once the consumer subscribes to a topic, Kafka will provide the current offset of the topic to the consumer and also saves the offset in the Zookeeper ensemble.
5. Consumer will request the Kafka in a regular interval (like 100 Ms) for new messages.
6. Once Kafka receives the messages from producers, it forwards these messages to the consumers.
7. Consumer will receive the message and process it.
8. Once the messages are processed, consumer will send an acknowledgement to the Kafka broker.
9. Once Kafka receives an acknowledgement, it changes the offset to the new value and updates it in the Zookeeper. Since offsets are maintained in the Zookeeper, the consumer can read next message correctly even during server outrages.

*This above flow will repeat until the consumer stops the request.
**Consumer has the option to rewind/skip to the desired offset of a topic at any time and read all the subsequent messages.

Type 2: Workflow of Queue Messaging / Consumer Group
In a queue messaging system instead of a single consumer, a group of consumers having the same Group ID will subscribe to a topic. In simple terms, consumers subscribing to a topic with same Group ID are considered as a single group and the messages are shared among them. 

1. Producers send message to a topic in a regular interval.
2. Kafka stores all messages in the partitions configured for that particular topic similar to the earlier scenario.
3. A single consumer subscribes to a specific topic, assume Topic-01 with Group ID as Group-1.
4. Kafka interacts with the consumer in the same way as Pub-Sub Messaging until new consumer subscribes the same topic, Topic-01 with the same Group ID as Group-1.
5. Once the new consumer arrives, Kafka switches its operation to share mode and shares the data between the two consumers. This sharing will go on until the number of con-sumers reach the number of partition configured for that particular topic.
6. Once the number of consumer exceeds the number of partitions, the new consumer will not receive any further message until any one of the existing consumer unsubscribes. This scenario arises because each consumer in Kafka will be assigned a minimum of one partition and once all the partitions are assigned to the existing consumers, the new consumers will have to wait.

This feature is also called as Consumer Group. In the same way, Kafka will provide the best of both the systems in a very simple and efficient manner.
